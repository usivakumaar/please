<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <title>Object Detection Camera Example</title>

</head>

<body>
  
  <p class="err" id="errorMessage"></p>
  <video id="videoInput" width="320px" height="240px" autoplay style="height:auto !important;width:100% !important;object-fit:cover;position:absolute"></video>
  <canvas id="canvasOutput" width="320px" height="240px" style="height:auto !important;width:100% !important;position:absolute;z-index:2222"></canvas>
  <script>
    var errorCallback = function (e) {
      console.log('Reeeejected!', e);
    };

    // Not showing vendor prefixes.
    navigator.getUserMedia({ video: { facingMode: 'environment' }, audio: false }, function (localMediaStream) {
      var video = document.querySelector('video');
      video.src = window.URL.createObjectURL(localMediaStream);
      //video.style.width = "420px";
      // Note: onloadedmetadata doesn't fire in Chrome when using it with getUserMedia.
      // See crbug.com/110938.
      video.onloadedmetadata = function (e) {
        // Ready to go. Do some stuff.
      };
    }, errorCallback);
  </script>
  <script src="adapter-5.0.4.js" type="text/javascript"></script>
  <script src="utils.js" type="text/javascript"></script>
  
  <script type="text/javascript">
    let utils = new Utils('errorMessage');
    

    let streaming = false;
    let videoInput = document.getElementById('videoInput');
    let startAndStop = document.getElementById('startAndStop');
    let canvasOutput = document.getElementById('canvasOutput');
    let canvasContext = canvasOutput.getContext('2d');



    function onVideoStarted() {
      streaming = true;
      startAndStop.innerText = 'Stop';
      videoInput.width = videoInput.videoWidth;
      videoInput.height = videoInput.videoHeight;
      utils.executeCode('codeEditor');
    }

    function onVideoStopped() {
      streaming = false;
      canvasContext.clearRect(0, 0, canvasOutput.width, canvasOutput.height);
      startAndStop.innerText = 'Start';
    }

    const FPS = 60;
    function processVideo() {
      try {
        
        
        let begin = Date.now();
        // start processing.
        cap.read(src);
        src.copyTo(dst);
        cv.cvtColor(dst, gray, cv.COLOR_RGBA2GRAY, 0);
        // detect faces.
        classifier.detectMultiScale(gray, faces, 1.1, 3, 0);
        // draw faces.
        ctx.clearRect(0, 0, c.width, c.height);
        //ctx.clearRect(0, 0, c.width, c.height);
        ctx.stroke();
        var points1,points2,height,width;
        for (let i = 0; i < faces.size(); ++i) {
          
          console.log(faces.get(i));
          let face = faces.get(i);
          // let point1 = new cv.Point(face.x, face.y);
          // let point2 = new cv.Point(face.x + face.width, face.y + face.height);
          // //cv.circle(dst,(point1,point2), 63, (0,0,255), -1);
          //cv.rectangle(dst, point1, point2, [255, 0, 0, 255]);
          //ctx.rect(face.x,face.y,150,100);
          //ctx.stroke();
          points1 = face.x;
          points2 = face.y;
          height = face.height;
          width = face.width;
        }
        //ctx.rect(points1,points2,150,100);
        //ctx.stroke();
        ctx.beginPath(); //
        ctx.rect(points1,points2,width,height);
        ctx.stroke();
        ctx.closePath();

        //cv.imshow('canvasOutput', dst);
        // schedule the next one.
        let delay = 1000 / FPS - (Date.now() - begin);
        setTimeout(processVideo, delay);
      } catch (err) {
          console.log(err);
      }
    };

    // schedule the first one.
    

    utils.loadOpenCv(() => {
      let faceCascadeFile = 'cascade.xml';
      utils.createFileFromUrl(faceCascadeFile, faceCascadeFile, () => {


        video = document.getElementById('videoInput');
        console.log(video);
        
        c=document.getElementById("canvasOutput");
        ctx=c.getContext("2d");
        src = new cv.Mat(video.height, video.width, cv.CV_8UC4);
        dst = new cv.Mat(video.height, video.width, cv.CV_8UC4);
        gray = new cv.Mat();
        cap = new cv.VideoCapture(video);
        faces = new cv.RectVector();
        classifier = new cv.CascadeClassifier();

        // load pre-trained classifiers
        classifier.load('cascade.xml');
        setTimeout(processVideo, 0);

      });
    });
  </script>
</body>

</html>